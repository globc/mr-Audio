WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: joeltschesche (joeltschesche-tu-darmstadt). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /home/atuin/g102ea/g102ea22/mr-Audio/wandb/run-20241216_163221-dwyemex5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Charades_20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/joeltschesche-tu-darmstadt/mr_BLIP
wandb: üöÄ View run at https://wandb.ai/joeltschesche-tu-darmstadt/mr_BLIP/runs/dwyemex5
2024-12-16 16:32:24,031 [INFO] 
=====  Running Parameters    =====
2024-12-16 16:32:24,031 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 4,
    "batch_size_train": 4,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "find_unused_parameters": true,
    "gpu": 0,
    "init_lr": 0.0003,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 50,
    "max_len": 200,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 8,
    "output_dir": "result/mr_BLIP/Charades/Charades_20-25",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "moment_retrieval",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "wandb": true,
    "wandb_name": "Charades_20",
    "wandb_project": "mr_BLIP",
    "warmup_lr": 1e-08,
    "warmup_steps": 1745,
    "weight_decay": 0.05,
    "world_size": 4
}
2024-12-16 16:32:24,031 [INFO] 
======  Dataset Attributes  ======
2024-12-16 16:32:24,031 [INFO] 
======== charades_sta =======
2024-12-16 16:32:24,032 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json"
            },
            "train": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/train.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/train.json"
            },
            "val": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json"
            }
        },
        "videos": {
            "storage": "/home/atuin/g102ea/shared/videos/Charades_v1"
        }
    },
    "data_type": "videos",
    "text_processor": {
        "eval": {
            "max_words": 50,
            "name": "blip_question"
        },
        "train": {
            "max_words": 50,
            "name": "blip_question"
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 224,
            "n_frms": 20,
            "name": "blip_video_eval"
        },
        "train": {
            "image_size": 224,
            "n_frms": 20,
            "name": "blip2_video_train"
        }
    }
}
2024-12-16 16:32:24,032 [INFO] 
======  Model Attributes  ======
2024-12-16 16:32:24,032 [INFO] {
    "arch": "blip2_mr",
    "drop_path_rate": 0,
    "finetuned": "",
    "frame_token_aggregation": false,
    "freeze_vit": true,
    "image_size": 224,
    "input_time_format": "seconds_integers",
    "interleave_data": true,
    "load_finetuned": false,
    "model_type": "pretrain_flant5xl",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth",
    "prompt": "",
    "t5_model": "google/flan-t5-xl",
    "task": "qformer_freeze_lora",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
2024-12-16 16:32:24,033 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/train.json.
2024-12-16 16:32:24,034 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/test.json.
2024-12-16 16:32:24,034 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/test.json.
2024-12-16 16:32:24,035 [INFO] Building datasets...
2024-12-16 16:32:59,764 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/eva_vit.py:433: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(cached_file, map_location="cpu")

2024-12-16 16:32:59,764 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/eva_vit.py:433: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(cached_file, map_location="cpu")

2024-12-16 16:32:59,764 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/eva_vit.py:433: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(cached_file, map_location="cpu")

2024-12-16 16:32:59,764 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/eva_vit.py:433: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(cached_file, map_location="cpu")

2024-12-16 16:33:09,745 [INFO] freeze vision encoder
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:24<00:24, 24.81s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:24<00:24, 24.70s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:24<00:24, 24.86s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:25<00:25, 25.27s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 13.99s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 15.61s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 13.94s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 15.55s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 14.09s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 15.76s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 14.03s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 15.65s/it]
2024-12-16 16:37:04,241 [INFO] Annoying numbers and their replacement: {112: 113, 128: 129, 135: 136, 161: 160, 162: 164, 163: 164, 170: 169, 171: 172, 173: 174, 175: 176, 181: 180, 182: 183, 191: 192, 193: 192, 194: 195}
2024-12-16 16:37:08,485 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_models/blip2.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(cached_file, map_location="cpu")

2024-12-16 16:37:08,485 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_models/blip2.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(cached_file, map_location="cpu")

2024-12-16 16:37:08,485 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_models/blip2.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(cached_file, map_location="cpu")

2024-12-16 16:37:08,485 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_models/blip2.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(cached_file, map_location="cpu")

2024-12-16 16:37:10,389 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth
2024-12-16 16:37:10,390 [INFO] load pretrained weights from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth
2024-12-16 16:37:10,673 [INFO] Start training
2024-12-16 16:37:12,053 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2024-12-16 16:37:12,054 [INFO] Loaded 12408 records for train split from the dataset.
2024-12-16 16:37:12,054 [INFO] Loaded 3720 records for val split from the dataset.
2024-12-16 16:37:12,054 [INFO] Loaded 3720 records for test split from the dataset.
2024-12-16 16:37:12,087 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py:147: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()

2024-12-16 16:37:12,091 [INFO] number of trainable parameters: 22825984
2024-12-16 16:37:12,093 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py:147: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()

2024-12-16 16:37:12,093 [INFO] Start training epoch 0, 775 iters per inner epoch.
2024-12-16 16:37:12,093 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py:147: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()

2024-12-16 16:37:12,096 [WARNING] /home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py:147: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()

[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 154, in <module>
[rank1]:     main()
[rank1]:   File "train.py", line 150, in main
[rank1]:     runner.train()
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 386, in train
[rank1]:     train_stats = self.train_epoch(cur_epoch)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 445, in train_epoch
[rank1]:     return self.task.train_epoch(
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 116, in train_epoch
[rank1]:     return self._train_inner_loop(
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/moment_retrieval.py", line 228, in _train_inner_loop
[rank1]:     samples = next(data_loader)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 152, in __next__
[rank1]:     data = next(self.iter_loader)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 65, in __iter__
[rank1]:     self.preload(loader_it)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 83, in preload
[rank1]:     self.batch = next(it)
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank1]:     data = self._next_data()
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
[rank1]:     return self._process_data(data)
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank1]:     data.reraise()
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
[rank1]:     raise exception
[rank1]: ImportError: Caught ImportError in DataLoader worker process 0.
[rank1]: Original Traceback (most recent call last):
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank1]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank1]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank1]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
[rank1]:     return self.datasets[dataset_idx][sample_idx]
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/moment_retrieval_dataset.py", line 31, in __getitem__
[rank1]:     frms, indices, fps, audio, sr = self.vis_processor(video_path, clip_proposal=clip)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/processors/blip_processors.py", line 321, in __call__
[rank1]:     clip, indices, fps, audio, sr = load_video_frames_with_audio(
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/intervals.py", line 43, in load_video_frames_with_audio
[rank1]:     video, audio, info = torchvision.io.read_video(video_path, pts_unit="sec")
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 275, in read_video
[rank1]:     _check_av_available()
[rank1]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 41, in _check_av_available
[rank1]:     raise av
[rank1]: ImportError: PyAV is not installed, and is necessary for the video operations in torchvision.
[rank1]: See https://github.com/mikeboers/PyAV#installation for instructions on how to
[rank1]: install PyAV on your system.


[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 154, in <module>
[rank3]:     main()
[rank3]:   File "train.py", line 150, in main
[rank3]:     runner.train()
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 386, in train
[rank3]:     train_stats = self.train_epoch(cur_epoch)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 445, in train_epoch
[rank3]:     return self.task.train_epoch(
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 116, in train_epoch
[rank3]:     return self._train_inner_loop(
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/moment_retrieval.py", line 228, in _train_inner_loop
[rank3]:     samples = next(data_loader)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 152, in __next__
[rank3]:     data = next(self.iter_loader)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 65, in __iter__
[rank3]:     self.preload(loader_it)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 83, in preload
[rank3]:     self.batch = next(it)
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank3]:     data = self._next_data()
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
[rank3]:     return self._process_data(data)
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank3]:     data.reraise()
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
[rank3]:     raise exception
[rank3]: ImportError: Caught ImportError in DataLoader worker process 0.
[rank3]: Original Traceback (most recent call last):
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank3]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank3]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank3]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
[rank3]:     return self.datasets[dataset_idx][sample_idx]
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/moment_retrieval_dataset.py", line 31, in __getitem__
[rank3]:     frms, indices, fps, audio, sr = self.vis_processor(video_path, clip_proposal=clip)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/processors/blip_processors.py", line 321, in __call__
[rank3]:     clip, indices, fps, audio, sr = load_video_frames_with_audio(
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/intervals.py", line 43, in load_video_frames_with_audio
[rank3]:     video, audio, info = torchvision.io.read_video(video_path, pts_unit="sec")
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 275, in read_video
[rank3]:     _check_av_available()
[rank3]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 41, in _check_av_available
[rank3]:     raise av
[rank3]: ImportError: PyAV is not installed, and is necessary for the video operations in torchvision.
[rank3]: See https://github.com/mikeboers/PyAV#installation for instructions on how to
[rank3]: install PyAV on your system.


[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 154, in <module>
[rank2]:     main()
[rank2]:   File "train.py", line 150, in main
[rank2]:     runner.train()
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 386, in train
[rank2]:     train_stats = self.train_epoch(cur_epoch)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 445, in train_epoch
[rank2]:     return self.task.train_epoch(
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 116, in train_epoch
[rank2]:     return self._train_inner_loop(
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/moment_retrieval.py", line 228, in _train_inner_loop
[rank2]:     samples = next(data_loader)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 152, in __next__
[rank2]:     data = next(self.iter_loader)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 65, in __iter__
[rank2]:     self.preload(loader_it)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 83, in preload
[rank2]:     self.batch = next(it)
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank2]:     data = self._next_data()
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
[rank2]:     return self._process_data(data)
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank2]:     data.reraise()
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
[rank2]:     raise exception
[rank2]: ImportError: Caught ImportError in DataLoader worker process 0.
[rank2]: Original Traceback (most recent call last):
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank2]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank2]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank2]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
[rank2]:     return self.datasets[dataset_idx][sample_idx]
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/moment_retrieval_dataset.py", line 31, in __getitem__
[rank2]:     frms, indices, fps, audio, sr = self.vis_processor(video_path, clip_proposal=clip)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/processors/blip_processors.py", line 321, in __call__
[rank2]:     clip, indices, fps, audio, sr = load_video_frames_with_audio(
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/intervals.py", line 43, in load_video_frames_with_audio
[rank2]:     video, audio, info = torchvision.io.read_video(video_path, pts_unit="sec")
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 275, in read_video
[rank2]:     _check_av_available()
[rank2]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 41, in _check_av_available
[rank2]:     raise av
[rank2]: ImportError: PyAV is not installed, and is necessary for the video operations in torchvision.
[rank2]: See https://github.com/mikeboers/PyAV#installation for instructions on how to
[rank2]: install PyAV on your system.


Traceback (most recent call last):
  File "train.py", line 154, in <module>
    main()
  File "train.py", line 150, in main
    runner.train()
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 386, in train
    train_stats = self.train_epoch(cur_epoch)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 445, in train_epoch
    return self.task.train_epoch(
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 116, in train_epoch
    return self._train_inner_loop(
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/moment_retrieval.py", line 228, in _train_inner_loop
    samples = next(data_loader)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 152, in __next__
    data = next(self.iter_loader)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 65, in __iter__
    self.preload(loader_it)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 83, in preload
    self.batch = next(it)
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
    return self._process_data(data)
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
    data.reraise()
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
ImportError: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/moment_retrieval_dataset.py", line 31, in __getitem__
    frms, indices, fps, audio, sr = self.vis_processor(video_path, clip_proposal=clip)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/processors/blip_processors.py", line 321, in __call__
    clip, indices, fps, audio, sr = load_video_frames_with_audio(
  File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/intervals.py", line 43, in load_video_frames_with_audio
    video, audio, info = torchvision.io.read_video(video_path, pts_unit="sec")
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 275, in read_video
    _check_av_available()
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 41, in _check_av_available
    raise av
ImportError: PyAV is not installed, and is necessary for the video operations in torchvision.
See https://github.com/mikeboers/PyAV#installation for instructions on how to
install PyAV on your system.


[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 154, in <module>
[rank0]:     main()
[rank0]:   File "train.py", line 150, in main
[rank0]:     runner.train()
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 386, in train
[rank0]:     train_stats = self.train_epoch(cur_epoch)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/runners/runner_base.py", line 445, in train_epoch
[rank0]:     return self.task.train_epoch(
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 116, in train_epoch
[rank0]:     return self._train_inner_loop(
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/moment_retrieval.py", line 228, in _train_inner_loop
[rank0]:     samples = next(data_loader)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 152, in __next__
[rank0]:     data = next(self.iter_loader)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 65, in __iter__
[rank0]:     self.preload(loader_it)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/dataloader_utils.py", line 83, in preload
[rank0]:     self.batch = next(it)
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
[rank0]:     return self._process_data(data)
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
[rank0]:     raise exception
[rank0]: ImportError: Caught ImportError in DataLoader worker process 0.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
[rank0]:     return self.datasets[dataset_idx][sample_idx]
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/datasets/datasets/moment_retrieval_dataset.py", line 31, in __getitem__
[rank0]:     frms, indices, fps, audio, sr = self.vis_processor(video_path, clip_proposal=clip)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/processors/blip_processors.py", line 321, in __call__
[rank0]:     clip, indices, fps, audio, sr = load_video_frames_with_audio(
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/intervals.py", line 43, in load_video_frames_with_audio
[rank0]:     video, audio, info = torchvision.io.read_video(video_path, pts_unit="sec")
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 275, in read_video
[rank0]:     _check_av_available()
[rank0]:   File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torchvision/io/video.py", line 41, in _check_av_available
[rank0]:     raise av
[rank0]: ImportError: PyAV is not installed, and is necessary for the video operations in torchvision.
[rank0]: See https://github.com/mikeboers/PyAV#installation for instructions on how to
[rank0]: install PyAV on your system.


W1216 16:37:33.128948 23158786611008 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2238485 closing signal SIGTERM
W1216 16:37:33.129710 23158786611008 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2238486 closing signal SIGTERM
W1216 16:37:33.129860 23158786611008 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2238487 closing signal SIGTERM
E1216 16:37:33.745186 23158786611008 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 2238484) of binary: /home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/bin/python
Traceback (most recent call last):
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/atuin/g102ea/g102ea22/software/private/conda/envs/mrBlipAudio/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-16_16:37:33
  host      : a0535.nhr.fau.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2238484)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
