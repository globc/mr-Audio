### Starting TaskPrologue of job 2245708 on a0832 at Mon Dec 16 20:21:45 CET 2024
Running on cores 64-127 with governor ondemand
Mon Dec 16 20:21:45 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   37C    P0             64W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:97:00.0 Off |                    0 |
| N/A   34C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:CD:00.0 Off |                    0 |
| N/A   33C    P0             58W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:D2:00.0 Off |                    0 |
| N/A   35C    P0             65W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

0,1,2,3
4
| distributed init (rank 0, world 4): env://
| distributed init (rank 1, world 4): env://
| distributed init (rank 3, world 4): env://
| distributed init (rank 2, world 4): env://
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [  0/775]  eta: 10:35:10  lr: 0.000000  loss: 3.4260  time: 49.1747  data: 0.0000  max mem: 45420
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [ 50/775]  eta: 1:02:39  lr: 0.000009  loss: 3.3153  time: 4.0564  data: 0.0000  max mem: 45708
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [100/775]  eta: 0:51:54  lr: 0.000017  loss: 2.9828  time: 4.0325  data: 0.0000  max mem: 45708
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 38, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 38, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 27, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 27, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [150/775]  eta: 0:46:02  lr: 0.000026  loss: 2.7342  time: 4.0695  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 27, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 27, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [200/775]  eta: 0:41:27  lr: 0.000034  loss: 0.8425  time: 4.0388  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [250/775]  eta: 0:37:27  lr: 0.000043  loss: 0.8446  time: 4.1125  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 27, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 27, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [300/775]  eta: 0:33:37  lr: 0.000052  loss: 0.7326  time: 4.1102  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 27, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 27, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 36, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 36, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [350/775]  eta: 0:29:53  lr: 0.000060  loss: 0.8730  time: 4.0640  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 38, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 38, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 35, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 35, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 38, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 38, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 37, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 37, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
Train: data epoch: [0]  [400/775]  eta: 0:26:14  lr: 0.000069  loss: 0.9545  time: 4.0363  data: 0.0000  max mem: 45723
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 29, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 29, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 28, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 28, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 31, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 31, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 34, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 34, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 32, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 32, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 30, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 30, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
audio_clip shape: torch.Size([4, 20, 48000])
audio shape: torch.Size([4, 20, 48000])
audio embdinngs shape: torch.Size([4, 20, 512])
emb shaoe: torch.Size([4, 20, 512])
frame_down_proj: torch.Size([80, 32, 512])
emb shaoe: torch.Size([80, 32, 512])
combined_video_audio_frame: torch.Size([80, 32, 1024])
fused_data: torch.Size([80, 32, 768])
frames_for_t5 after reshaping: torch.Size([4, 640, 2048])
Starting Prompt Concat
video_prompt_embs Shape: torch.Size([4, 662, 2048])
text_prompt_embs Shape: torch.Size([4, 33, 2048])
interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, video_prompt_embs Shape: torch.Size([4, 662, 2048])
After reshaping, text_prompt_embs Shape: torch.Size([4, 33, 2048])
After reshaping, interleaved_video_prompt_embs Shape: torch.Size([4, 662, 2048])
[1;34mwandb[0m:  View run [33mCharades_20[0m at: [34mhttps://wandb.ai/joeltschesche-tu-darmstadt/mr_BLIP/runs/qtgjiz5h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241216_202205-qtgjiz5h/logs[0m
=== JOB_STATISTICS ===
=== current date     : Mon Dec 16 20:55:39 CET 2024
= Job-ID             : 2245708 on alex
= Job-Name           : mr_audio_charades
= Job-Command        : /home/atuin/g102ea/g102ea22/mr-Audio/train_charades_sta.sh
= Initial workdir    : /home/atuin/g102ea/g102ea22/mr-Audio
= Queue/Partition    : a100
= Slurm account      : g102ea with QOS=normal
= Features           : a100_80
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:33:53
= Total RAM usage    : 532.4 GiB of assigned  GiB (%)
= Node list          : a0832
= Subm/Elig/Start/End: 2024-12-16T20:21:44 / 2024-12-16T20:21:44 / 2024-12-16T20:21:45 / 2024-12-16T20:55:38
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           44.6G   104.9G   209.7G        N/A     102K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-80GB, 00000000:91:00.0, 414491, 93 %, 30 %, 34548 MiB, 86414219 ms
NVIDIA A100-SXM4-80GB, 00000000:91:00.0, 533262, 38 %, 11 %, 57770 MiB, 2011842 ms
NVIDIA A100-SXM4-80GB, 00000000:97:00.0, 414492, 93 %, 29 %, 34680 MiB, 86412550 ms
NVIDIA A100-SXM4-80GB, 00000000:97:00.0, 533263, 38 %, 11 %, 67826 MiB, 2016311 ms
NVIDIA A100-SXM4-80GB, 00000000:CD:00.0, 414493, 93 %, 30 %, 35384 MiB, 86406532 ms
NVIDIA A100-SXM4-80GB, 00000000:CD:00.0, 533264, 39 %, 11 %, 78380 MiB, 2017087 ms
NVIDIA A100-SXM4-80GB, 00000000:D2:00.0, 414494, 93 %, 29 %, 35836 MiB, 86404159 ms
NVIDIA A100-SXM4-80GB, 00000000:D2:00.0, 533265, 39 %, 11 %, 57958 MiB, 2016635 ms
