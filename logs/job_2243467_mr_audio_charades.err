WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
[rank0]:[W1215 23:09:18.047793375 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W1215 23:09:18.050530526 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W1215 23:09:18.054928940 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W1215 23:09:23.589813802 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: joeltschesche (joeltschesche-tu-darmstadt). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /home/atuin/g102ea/g102ea22/mr-Audio/wandb/run-20241215_230926-iudpw5ow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Charades_20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/joeltschesche-tu-darmstadt/mr_BLIP
wandb: üöÄ View run at https://wandb.ai/joeltschesche-tu-darmstadt/mr_BLIP/runs/iudpw5ow
2024-12-15 23:09:27,268 [INFO] 
=====  Running Parameters    =====
2024-12-15 23:09:27,269 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 4,
    "batch_size_train": 4,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "find_unused_parameters": true,
    "gpu": 0,
    "init_lr": 0.0003,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 50,
    "max_len": 200,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 8,
    "output_dir": "result/mr_BLIP/Charades/Charades_20-5",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "moment_retrieval",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "wandb": true,
    "wandb_name": "Charades_20",
    "wandb_project": "mr_BLIP",
    "warmup_lr": 1e-08,
    "warmup_steps": 1745,
    "weight_decay": 0.05,
    "world_size": 4
}
2024-12-15 23:09:27,269 [INFO] 
======  Dataset Attributes  ======
2024-12-15 23:09:27,269 [INFO] 
======== charades_sta =======
2024-12-15 23:09:27,270 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json"
            },
            "train": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/train.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/train.json"
            },
            "val": {
                "storage": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json",
                "url": "/home/atuin/g102ea/shared/charades_sta_annotations/test.json"
            }
        },
        "videos": {
            "storage": "/home/atuin/g102ea/shared/videos/Charades_v1"
        }
    },
    "data_type": "videos",
    "text_processor": {
        "eval": {
            "max_words": 50,
            "name": "blip_question"
        },
        "train": {
            "max_words": 50,
            "name": "blip_question"
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 224,
            "n_frms": 20,
            "name": "blip_video_eval"
        },
        "train": {
            "image_size": 224,
            "n_frms": 20,
            "name": "blip2_video_train"
        }
    }
}
2024-12-15 23:09:27,270 [INFO] 
======  Model Attributes  ======
2024-12-15 23:09:27,270 [INFO] {
    "arch": "blip2_mr",
    "drop_path_rate": 0,
    "finetuned": "",
    "frame_token_aggregation": false,
    "freeze_vit": true,
    "image_size": 224,
    "input_time_format": "seconds_integers",
    "interleave_data": true,
    "load_finetuned": false,
    "model_type": "pretrain_flant5xl",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth",
    "prompt": "",
    "t5_model": "google/flan-t5-xl",
    "task": "qformer_freeze_lora",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
2024-12-15 23:09:27,271 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/train.json.
2024-12-15 23:09:27,272 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/test.json.
2024-12-15 23:09:27,272 [INFO] Using existing file /home/atuin/g102ea/shared/charades_sta_annotations/test.json.
2024-12-15 23:09:27,273 [INFO] Building datasets...
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 154, in <module>
[rank3]:     main()
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 144, in main
[rank3]:     model = task.build_model(cfg)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 38, in build_model
[rank3]:     return model_cls.from_config(model_config)
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 986, in from_config
[rank3]:     model = cls(
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 112, in __init__
[rank3]:     self.audio_embeddings_model = CLAPAudioEmbeddings()
[rank3]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/AudioEmbeddingsCLAP.py", line 26, in __init__
[rank3]:     self.processor.to(self.eigendevice)
[rank3]: AttributeError: 'ClapProcessor' object has no attribute 'to'
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 154, in <module>
[rank2]:     main()
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 144, in main
[rank2]:     model = task.build_model(cfg)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 38, in build_model
[rank2]:     return model_cls.from_config(model_config)
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 986, in from_config
[rank2]:     model = cls(
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 112, in __init__
[rank2]:     self.audio_embeddings_model = CLAPAudioEmbeddings()
[rank2]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/AudioEmbeddingsCLAP.py", line 26, in __init__
[rank2]:     self.processor.to(self.eigendevice)
[rank2]: AttributeError: 'ClapProcessor' object has no attribute 'to'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 154, in <module>
[rank1]:     main()
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 144, in main
[rank1]:     model = task.build_model(cfg)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 38, in build_model
[rank1]:     return model_cls.from_config(model_config)
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 986, in from_config
[rank1]:     model = cls(
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 112, in __init__
[rank1]:     self.audio_embeddings_model = CLAPAudioEmbeddings()
[rank1]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/AudioEmbeddingsCLAP.py", line 26, in __init__
[rank1]:     self.processor.to(self.eigendevice)
[rank1]: AttributeError: 'ClapProcessor' object has no attribute 'to'
Traceback (most recent call last):
  File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 154, in <module>
    main()
  File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 144, in main
    model = task.build_model(cfg)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 38, in build_model
    return model_cls.from_config(model_config)
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 986, in from_config
    model = cls(
  File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 112, in __init__
    self.audio_embeddings_model = CLAPAudioEmbeddings()
  File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/AudioEmbeddingsCLAP.py", line 26, in __init__
    self.processor.to(self.eigendevice)
AttributeError: 'ClapProcessor' object has no attribute 'to'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 154, in <module>
[rank0]:     main()
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/train.py", line 144, in main
[rank0]:     model = task.build_model(cfg)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/tasks/base_task.py", line 38, in build_model
[rank0]:     return model_cls.from_config(model_config)
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 986, in from_config
[rank0]:     model = cls(
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/lavis/models/blip2_mr_models/blip2_mr.py", line 112, in __init__
[rank0]:     self.audio_embeddings_model = CLAPAudioEmbeddings()
[rank0]:   File "/home/atuin/g102ea/g102ea22/mr-Audio/audioinclusion/AudioEmbeddingsCLAP.py", line 26, in __init__
[rank0]:     self.processor.to(self.eigendevice)
[rank0]: AttributeError: 'ClapProcessor' object has no attribute 'to'
[rank0]:[W1215 23:09:31.940328460 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1215 23:09:32.025851 833608 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 834096 closing signal SIGTERM
W1215 23:09:32.026610 833608 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 834099 closing signal SIGTERM
E1215 23:09:32.492305 833608 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 834097) of binary: /home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/bin/python
Traceback (most recent call last):
  File "/apps/python/3.9-anaconda/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/apps/python/3.9-anaconda/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/run.py", line 923, in <module>
    main()
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/atuin/g102ea/g102ea22/venvs/mrBlipAudio/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-12-15_23:09:32
  host      : a0603.nhr.fau.de
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 834098)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-15_23:09:32
  host      : a0603.nhr.fau.de
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 834097)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
